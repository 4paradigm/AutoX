{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2827085c-166a-4866-a3f8-4781a5edba1d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade mxnet\n",
    "# !pip install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a7936f7-a1c7-431f-984e-6b71904dfcf6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.text import TextPredictor\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('sub_train.csv')\n",
    "test_data = pd.read_csv('sub_val.csv')\n",
    "test_data_nolab = test_data.drop(columns=['target']) \n",
    "time_limit = 1 * 60  # set to larger value in your applications\n",
    "# predictor = TextPredictor(label='target', path='autogluon')\n",
    "# predictor.fit(train_data, time_limit=time_limit)\n",
    "# y_pred = predictor.predict(test_data_nolab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb6dacba-82f6-43ff-aad3-7513acf4b8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# import numpy as np\n",
    "# RMSE = np.sqrt(mean_squared_error(test_data['target'], y_pred))\n",
    "# RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e1de78-0179-4881-8f37-f585b5635ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "def count_time(func):\n",
    "    def int_time():\n",
    "        start_time = time.time()\n",
    "        func()\n",
    "        over_time = time.time()\n",
    "        total_time = over_time - start_time\n",
    "        print(\"程序运行了%s秒\" % total_time)\n",
    "    return int_time\n",
    "\n",
    "def count_info(func):\n",
    "    def float_info():\n",
    "        pid = os.getpid()\n",
    "        p = psutil.Process(pid)\n",
    "        info_start = p.memory_full_info().uss/1024\n",
    "        func()\n",
    "        info_end=p.memory_full_info().uss/1024\n",
    "        print(\"程序占用了内存\"+str(info_end-info_start)+\"KB\")\n",
    "    return float_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a317c9f-d8a8-4bed-a88c-4e88e7ae8aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon\"\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                | Params\n",
      "----------------------------------------------------------\n",
      "0 | model             | MultimodalFusionMLP | 109 M \n",
      "1 | validation_metric | MeanSquaredError    | 0     \n",
      "2 | loss_func         | MSELoss             | 0     \n",
      "----------------------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "219.565   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226176af83b944fc9e01f00d3b4418e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 5: val_rmse reached 1.99957 (best 1.99957), saving model to \"/root/autodl-tmp/commonlitreadabilityprize/autogluon/epoch=0-step=5.ckpt\" as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 11: val_rmse reached 1.07678 (best 1.07678), saving model to \"/root/autodl-tmp/commonlitreadabilityprize/autogluon/epoch=0-step=11.ckpt\" as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 17: val_rmse reached 0.74369 (best 0.74369), saving model to \"/root/autodl-tmp/commonlitreadabilityprize/autogluon/epoch=1-step=17.ckpt\" as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 23: val_rmse reached 0.96483 (best 0.74369), saving model to \"/root/autodl-tmp/commonlitreadabilityprize/autogluon/epoch=1-step=23.ckpt\" as top 3\n",
      "Time limit reached. Elapsed time is 0:01:00. Signaling Trainer to stop.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 26: val_rmse reached 0.71043 (best 0.71043), saving model to \"/root/autodl-tmp/commonlitreadabilityprize/autogluon/epoch=2-step=26.ckpt\" as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7305b2bc02a4c07bbd5caae22e2e993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "程序占用了内存6525236.0KB\n",
      "程序运行了101.66942572593689秒\n"
     ]
    }
   ],
   "source": [
    "@count_time\n",
    "@count_info\n",
    "def calcu_atg():\n",
    "    predictor = TextPredictor(label='target', path='autogluon')\n",
    "    predictor.fit(train_data, time_limit=time_limit)\n",
    "    embeddings = predictor.extract_embedding(train_data)\n",
    "    embeddings.shape\n",
    "    \n",
    "calcu_atg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84578e6-e45f-47a7-bda4-e608a57f3a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
